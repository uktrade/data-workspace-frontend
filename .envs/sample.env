DEBUG=True

AUTHBROKER_CLIENT_ID=some-id
AUTHBROKER_CLIENT_SECRET=some-secret
AUTHBROKER_URL=https://url.to.staff.sso/

ADMIN_DB__HOST=data-workspace-postgres
ADMIN_DB__NAME=dataworkspace
ADMIN_DB__PASSWORD=postgres
ADMIN_DB__PORT=5432
ADMIN_DB__USER=postgres
ALLOWED_HOSTS__1=dataworkspace.test
ALLOWED_HOSTS__2=.dataworkspace.test
ALLOWED_HOSTS__3=data-workspace
ALLOWED_HOSTS__4=.data-workspace
NOTEBOOKS_URL=something


AWS_DEFAULT_REGION=eu-west-2

# for local development these should be the same as your docker-compose.yml/data-workspace-minio values
AWS_ACCESS_KEY_ID=some-key
AWS_SECRET_ACCESS_KEY=some-secret

# Optional AWS local endpoints for local dev
# These should point to your localstack instance
# S3_LOCAL_ENDPOINT_URL=http://data-infrastructure-localstack:4566
# STS_LOCAL_ENDPOINT_URL=http://data-infrastructure-localstack:4566



APPLICATION_ROOT_DOMAIN=dataworkspace.test:8000
APPLICATION_TEMPLATES__1__NICE_NAME=Jupyter lab process
APPLICATION_TEMPLATES__1__HOST_BASENAME=jupyterlabprocess
APPLICATION_TEMPLATES__1__SPAWNER=PROCESS
APPLICATION_TEMPLATES__1__SPAWNER_TIME=120
APPLICATION_TEMPLATES__1__SPAWNER_OPTIONS__CMD__1=python3
APPLICATION_TEMPLATES__1__SPAWNER_OPTIONS__CMD__2=-m
APPLICATION_TEMPLATES__1__SPAWNER_OPTIONS__CMD__3=http.server
APPLICATION_TEMPLATES__1__SPAWNER_OPTIONS__CMD__4=8888
APPLICATION_TEMPLATES__2__NICE_NAME=Jupyter lab fargate
APPLICATION_TEMPLATES__2__HOST_BASENAME=jupyterlabfargate
APPLICATION_TEMPLATES__2__SPAWNER=FARGATE
APPLICATION_TEMPLATES__2__SPAWNER_TIME=120
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__1=jupyter
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__2=lab
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__3=--NotebookApp.token=''
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__4=--NotebookApp.ip='127.0.0.1'
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__5=--NotebookApp.allow_remote_access=True
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CMD__6=--NotebookApp.port=8888
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__ROLE_ARN=jdev-michal.charemza@digital.trade.gov.uk
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CLUSTER_NAME=analysisworkspace-dev-notebooks
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__CONTAINER_NAME=jupyterhub-notebook
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__DEFINITION_ARN=analysisworkspace-dev-notebook:3
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__SECURITY_GROUPS__1=sg-something
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__SUBNETS__1=subnet-something
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__ENV__DUMMY=value
APPLICATION_TEMPLATES__2__SPAWNER_OPTIONS__PORT=8888
APPSTREAM_AWS_ACCESS_KEY=access-key
APPSTREAM_AWS_REGION=region
APPSTREAM_AWS_SECRET_KEY=secret-key
APPSTREAM_FLEET_NAME=fleet-name
APPSTREAM_STACK_NAME=stack-name
APPSTREAM_URL=https://url.to.appstream/
DATA_DB__datasets__HOST=data-workspace-postgres
DATA_DB__datasets__NAME=datasets
DATA_DB__datasets__PASSWORD=postgres
DATA_DB__datasets__PORT=5432
DATA_DB__datasets__USER=postgres
PROMETHEUS_DOMAIN=some.domain.com
METRICS_SERVICE_DISCOVERY_BASIC_AUTH_USER=user
METRICS_SERVICE_DISCOVERY_BASIC_AUTH_PASSWORD=password
REDIS_URL=redis://data-workspace-redis:6379
SECRET_KEY=something-secret
S3_ASSUME_ROLE_POLICY_DOCUMENT_BASE64=e30=
S3_POLICY_NAME=my-policy
S3_POLICY_DOCUMENT_TEMPLATE_BASE64=e30=
S3_PERMISSIONS_BOUNDARY_ARN=my-arn
S3_ROLE_PREFIX=my-prefix

ZENDESK_EMAIL=test@test.com
# ZENDESK_SUBDOMAIN just requires the subdomain part not the full url
# i.e. for subdomain.zendesk.com the value should be subdomain
ZENDESK_SUBDOMAIN=subdomain
ZENDESK_TOKEN=abcd

# ZENDESK_SERVICE_FIELD_ID is a numeric value for a custom field within zendesk which is
# set to the ZENDESK_SERVIE_FIELD_VALUE when requesting access to datasets zendesk.py
ZENDESK_SERVICE_FIELD_ID=numeric_field_id
ZENDESK_SERVICE_FIELD_VALUE=field_value

NOTIFY_API_KEY=notify-token
FERNET_EMAIL_TOKEN_KEY=generate-using-fernet-generate-key

# this is default value for local development
UPLOADS_BUCKET=uploads
MIRROR_REMOTE_ROOT=xxx

X_FORWARDED_FOR_TRUSTED_HOPS=1
APPLICATION_IP_WHITELIST__1=0.0.0.0/0

HAWK_SENDERS__1__id=testhawkid
HAWK_SENDERS__1__key=aaaaaaaaaaaaaaaaaaaaaaaaaa
HAWK_SENDERS__1__ALGORITHM=sha256

GITLAB_URL=https://gitab.example.test/
GITLAB_TOKEN=not-a-token
GITLAB_VISUALISATIONS_GROUP=visualisations
GITLAB_ECR_PROJECT_ID=4
GITLAB_ECR_PROJECT_TRIGGER_TOKEN=some-token

GITLAB_URL_FOR_TOOLS=https://gitlab.local

SUPERSET_ROOT=http://host.docker.internal:8000/
FLOWER_ROOT=http://flower.example.test/

QUICKSIGHT_USER_REGION=get-from-aws-quicksight
QUICKSIGHT_VPC_ARN=get-from-aws-quicksight
QUICKSIGHT_DASHBOARD_EMBEDDING_ROLE_ARN=aws:arn:from:terraform
QUICKSIGHT_AUTHOR_CUSTOM_PERMISSIONS=custom-author-permissions

REFERENCE_DATASET_PREVIEW_NUM_OF_ROWS=1000
DATASET_PREVIEW_NUM_OF_ROWS=10

EFS_ID=some-id

EXPLORER_CONNECTIONS={"datasets": "datasets"}
EXPLORER_DEFAULT_CONNECTION=datasets

VISUALISATION_CLOUDWATCH_LOG_GROUP=analysisworkspace-dev-notebook

# Optional - for remote debugging of docker containers
PYTHONBREAKPOINT=remote_pdb.set_trace
REMOTE_PDB_HOST=0.0.0.0
REMOTE_PDB_PORT=4444
GEVENT_SUPPORT=True

ACTIVITY_STREAM_BASE_URL=https://url.to.activity.stream/
ACTIVITY_STREAM_HAWK_CREDENTIALS_ID=some-id
ACTIVITY_STREAM_HAWK_CREDENTIALS_KEY=some-key

PYTHONUNBUFFERED=TRUE

PGAUDIT_LOG_SCOPES='ALL, -MISC'
PGAUDIT_LOG_TYPE=docker
DATASETS_DB_INSTANCE_ID=rds-datasets-db-id

DATAFLOW_BASE_URL=https://data-flow-dev.london.cloudapps.digital
DATAFLOW_HAWK_ID=get-from-vault
DATAFLOW_HAWK_KEY=get-from-vaule
DATAFLOW_S3_IMPORT_DAG=DataWorkspaceS3ImportPipeline

DATASET_FINDER_ES_HOST=http://data-workspace-es
DATASET_FINDER_ES_PORT=9200
DATASET_FINDER_ES_INSECURE=True
DATASET_FINDER_AWS_REGION=eu-west-2
DATASET_FINDER_DB_NAME=my_database

TEAMS_DATA_WORKSPACE_COMMUNITY_URL=https://example.com/msteams
DATA_WORKSPACE_ROADMAP_URL=https://example.com/roadmap


CLAMAV_URL=http://clam_av_host/v2/scan
CLAMAV_USER=clam_av_username
CLAMAV_PASSWORD=clam_av_password

GECKOBOARD_API_KEY=key_for_gecko_board

